# ğŸŒ¿ MLOps Project - Dandelion vs Grass Classifier

## ğŸ“‹ Description du Projet

Projet MLOps complet pour classifier des images : **Pissenlit (Dandelion)** vs **Herbe (Grass)**.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Airflow   â”‚â”€â”€â”€â”€â–¶â”‚  MinIO   â”‚â”€â”€â”€â”€â–¶â”‚  DL      â”‚â”€â”€â”€â”€â–¶â”‚ MLflow   â”‚
â”‚  (Orchestre)â”‚     â”‚ (Storage)â”‚     â”‚  Model   â”‚     â”‚ (Track)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â”‚
                                                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WebApp    â”‚â”€â”€â”€â”€â–¶â”‚   API    â”‚â”€â”€â”€â”€â–¶â”‚  MinIO   â”‚     â”‚Monitoringâ”‚
â”‚  (Frontend) â”‚     â”‚ (Backend) â”‚     â”‚ (Models) â”‚     â”‚ (Metrics) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–²
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Kubernetes   â”‚
                    â”‚ (OrchestrÃ©)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Installation et DÃ©marrage

### PrÃ©requis
- **Docker** & **Docker Compose** (version rÃ©cente)
- **Python 3.9+**
- **Git**

### Ã‰tape 1 : Cloner le projet

```bash
git clone https://github.com/nolpen6/ML_Ops_Final_Project.git
cd ML_Ops_Final_Project
```

### Ã‰tape 2 : Configuration de l'environnement

1. **CrÃ©er le fichier `.env`** (copier depuis `.env.example` si disponible) :
```bash
# GÃ©nÃ©rer une clÃ© Fernet pour Airflow
python3 -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```

2. **CrÃ©er le fichier `.env`** Ã  la racine du projet :
```bash
AIRFLOW_FERNET_KEY=<la_clÃ©_gÃ©nÃ©rÃ©e>
```

### Ã‰tape 3 : PrÃ©parer les donnÃ©es (optionnel)

Si tu as des images d'entraÃ®nement, place-les dans :
```
data/
â”œâ”€â”€ dandelion/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ grass/
    â”œâ”€â”€ image1.jpg
    â””â”€â”€ ...
```

### Ã‰tape 4 : Lancer les services Docker

```bash
docker compose up -d
```

**â±ï¸ Attendre 2-3 minutes** que tous les services dÃ©marrent (surtout Airflow).

VÃ©rifier que tous les services sont en cours d'exÃ©cution :
```bash
docker compose ps
```

### Ã‰tape 5 : Configurer l'environnement Python

```bash
# CrÃ©er un environnement virtuel
python3 -m venv venv

# Activer l'environnement
# Sur macOS/Linux :
source venv/bin/activate
# Sur Windows :
# venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Ã‰tape 6 : Initialiser la base de donnÃ©es PostgreSQL

```bash
# CrÃ©er la table predictions
python scripts/init_predictions_db.py

# CrÃ©er le bucket MinIO pour les prÃ©dictions
python scripts/create_predictions_bucket.py
```

### Ã‰tape 7 : Lancer l'API

```bash
# Dans le venv activÃ©
uvicorn scripts.api:app --reload
```

L'API sera accessible sur : http://localhost:8000
Documentation Swagger : http://localhost:8000/docs

### Ã‰tape 8 : Utiliser les DAGs Airflow

1. **AccÃ©der Ã  Airflow** : http://localhost:8080
   - Username : `admin`
   - Password : `admin`

2. **ExÃ©cuter le DAG d'ingestion de donnÃ©es** :
   - Trouver le DAG `data_ingestion`
   - Cliquer sur le bouton â–¶ï¸ (Play) pour dÃ©clencher manuellement
   - Attendre que les tÃ¢ches `scan_images` et `upload_to_minio` passent au vert âœ…

3. **ExÃ©cuter le DAG d'entraÃ®nement** :
   - Trouver le DAG `training`
   - Cliquer sur le bouton â–¶ï¸ (Play) pour dÃ©clencher manuellement
   - Attendre la fin de l'entraÃ®nement (2-5 minutes)
   - VÃ©rifier les runs dans MLflow : http://localhost:5001

## ğŸŒ Services Disponibles

| Service | URL | Identifiants |
|---------|-----|--------------|
| **Airflow** | http://localhost:8080 | admin / admin |
| **MinIO Console** | http://localhost:9001 | minioadmin / minioadmin |
| **MLflow** | http://localhost:5001 | - |
| **pgAdmin** | http://localhost:5050 | admin@mlops.com / admin |
| **API FastAPI** | http://localhost:8000 | - |
| **API Docs** | http://localhost:8000/docs | - |
| **Prometheus** | http://localhost:9090 | - |
| **Grafana** | http://localhost:3000 | admin / admin |

## ğŸ“– Utilisation

### Faire une prÃ©diction via l'API

1. Aller sur http://localhost:8000/docs
2. Utiliser l'endpoint `POST /predict/`
3. Uploader une image (dandelion ou grass)
4. La rÃ©ponse contient :
   - La prÃ©diction (dandelion ou grass)
   - Le niveau de confiance
   - L'ID de la prÃ©diction
   - Le chemin MinIO de l'image sauvegardÃ©e

### Voir les prÃ©dictions stockÃ©es

- **Dans MinIO** : http://localhost:9001 â†’ bucket `mlops-predictions`
- **Dans PostgreSQL** : http://localhost:5050 (pgAdmin) â†’ table `predictions`
- **Via l'API** : http://localhost:8000/predictions/

### Voir les runs d'entraÃ®nement

- **MLflow** : http://localhost:5001 â†’ ExpÃ©rience "dandelion_vs_grass_classifier"

## ğŸ“ Structure du Projet

```
emmaloou-ML_Ops/
â”œâ”€â”€ scripts/              # Scripts Python
â”‚   â”œâ”€â”€ api.py           # API FastAPI
â”‚   â”œâ”€â”€ webapp.py        # WebApp Streamlit
â”‚   â”œâ”€â”€ model_train.py   # EntraÃ®nement
â”‚   â””â”€â”€ ...
â”œâ”€â”€ dags/                # DAGs Airflow
â”‚   â”œâ”€â”€ data_ingestion_dag.py
â”‚   â””â”€â”€ training_dag.py
â”œâ”€â”€ docker/              # Dockerfiles
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”œâ”€â”€ Dockerfile.webapp
â”‚   â””â”€â”€ Dockerfile.airflow
â”œâ”€â”€ kubernetes/          # Manifests K8s
â”‚   â”œâ”€â”€ api-deployment.yaml
â”‚   â”œâ”€â”€ webapp-deployment.yaml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ monitoring/          # Config Monitoring
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/
â”œâ”€â”€ config/              # Configurations
â”‚   â”œâ”€â”€ airflow_config.yaml
â”‚   â””â”€â”€ mlflow_config.yaml
â”œâ”€â”€ docker-compose.yml   # Services Docker
â”œâ”€â”€ requirements.txt     # DÃ©pendances
â””â”€â”€ README.md
```

## ğŸ”§ Technologies

- **Orchestration** : Apache Airflow, Kubernetes
- **ML** : PyTorch, MLflow
- **Storage** : MinIO (S3-compatible)
- **API** : FastAPI
- **Frontend** : Streamlit
- **Monitoring** : Prometheus, Grafana
- **CI/CD** : GitHub Actions
- **Containerization** : Docker

## ğŸ“Š ModÃ¨le

- **Architecture** : ResNet18 avec Transfer Learning
- **Classes** : Dandelion (0), Grass (1)
- **Input** : Images 128x128 RGB
- **Performance** : 83.33% accuracy

## ğŸ”§ Configuration pgAdmin (Interface PostgreSQL)

1. AccÃ©der Ã  http://localhost:5050
2. Se connecter avec : `admin@mlops.com` / `admin`
3. Ajouter un nouveau serveur :
   - **Name** : MLOps PostgreSQL
   - **Host** : `postgres` (nom du service Docker)
   - **Port** : `5432`
   - **Database** : `mlops`
   - **Username** : `airflow`
   - **Password** : `airflow`
4. Explorer la table `predictions` pour voir toutes les prÃ©dictions

## ğŸ› Troubleshooting

### L'API ne dÃ©marre pas
- VÃ©rifier que le venv est activÃ© : `which python` doit pointer vers `venv/bin/python`
- VÃ©rifier que toutes les dÃ©pendances sont installÃ©es : `pip list | grep psycopg2`
- VÃ©rifier que le modÃ¨le existe : `ls models/best_model_epoch_3.pth`

### Les DAGs Airflow ne s'exÃ©cutent pas
- VÃ©rifier que PostgreSQL est accessible : `docker ps | grep postgres`
- VÃ©rifier les logs : `docker logs mlops-airflow-scheduler`
- Attendre que Airflow soit complÃ¨tement initialisÃ© (2-3 minutes)

### MLflow ne montre pas les runs
- VÃ©rifier que MLflow est dÃ©marrÃ© : `docker ps | grep mlflow`
- VÃ©rifier que le DAG training a bien Ã©tÃ© exÃ©cutÃ©
- RedÃ©marrer MLflow : `docker compose restart mlflow`

### MinIO ne montre pas les images
- VÃ©rifier que MinIO est dÃ©marrÃ© : `docker ps | grep minio`
- VÃ©rifier que le DAG data_ingestion a Ã©tÃ© exÃ©cutÃ©
- VÃ©rifier les buckets : http://localhost:9001

### PostgreSQL ne contient pas de donnÃ©es
- VÃ©rifier que la table existe : `python scripts/init_predictions_db.py`
- VÃ©rifier que l'API sauvegarde bien : regarder les logs de l'API lors d'une prÃ©diction

## ğŸ”„ Commandes Utiles

```bash
# Voir les logs d'un service
docker logs mlops-airflow-scheduler
docker logs mlops-mlflow
docker logs mlops-postgres

# RedÃ©marrer un service
docker compose restart <service_name>

# ArrÃªter tous les services
docker compose down

# ArrÃªter et supprimer les volumes (âš ï¸ supprime les donnÃ©es)
docker compose down -v

# Voir l'Ã©tat des services
docker compose ps
```

## ğŸ“ Notes Importantes

- **Premier dÃ©marrage** : Airflow prend 2-3 minutes pour s'initialiser complÃ¨tement
- **ModÃ¨le** : Le modÃ¨le doit Ãªtre entraÃ®nÃ© avant de pouvoir faire des prÃ©dictions (via le DAG `training`)
- **DonnÃ©es** : Les images d'entraÃ®nement doivent Ãªtre dans `data/dandelion/` et `data/grass/`
- **Ports** : Assure-toi que les ports 8000, 8080, 5001, 9000, 9001, 5433, 5050 ne sont pas dÃ©jÃ  utilisÃ©s

## ğŸ“ License

Ce projet est un projet Ã©ducatif.
