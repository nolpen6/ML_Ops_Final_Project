# ğŸ”„ Configuration d'Airflow

## ğŸ“‹ Ce qui va Ãªtre fait

1. âœ… CrÃ©er les dossiers Airflow (`AIRFLOW_HOME`)
2. âœ… Initialiser la base de donnÃ©es (SQLite pour simplifier)
3. âœ… CrÃ©er les premiers DAGs
4. âœ… Lancer Airflow webserver et scheduler

---

## ğŸ—‚ï¸ Structure CrÃ©Ã©e

```
emmaloou-ML_Ops/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/              # DAGs Airflow
â”‚   â”œâ”€â”€ logs/              # Logs des tÃ¢ches
â”‚   â”œâ”€â”€ plugins/           # Plugins personnalisÃ©s
â”‚   â””â”€â”€ config/            # Configurations Airflow
```

---

## ğŸš€ Commandes pour Lancer Airflow

### Initialiser la DB
```bash
cd "/Users/matthieudollfus/Documents/Master 2/MLOps/emmaloou-ML_Ops"
export AIRFLOW_HOME=$(pwd)/airflow
source venv/bin/activate

# Initialiser la base de donnÃ©es
airflow db init

# CrÃ©er un utilisateur admin
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname Admin \
    --role Admin \
    --email admin@example.com \
    --password admin
```

### Lancer Airflow (2 terminaux)

**Terminal 1 - Scheduler** :
```bash
airflow scheduler
```

**Terminal 2 - Webserver** :
```bash
airflow webserver --port 8080
```

### AccÃ©der Ã  l'interface
http://localhost:8080
- Username : `admin`
- Password : `admin`

---

## âš™ï¸ Pour Simplifier : Utiliser la Version SimplifiÃ©e

Pour Ã©viter de configurer Airflow complet maintenant, nous allons :
1. CrÃ©er les DAGs dans le dossier `dags/`
2. Utiliser une version plus simple avec Docker plus tard
3. Se concentrer sur la crÃ©ation des DAGs

---

## ğŸ“ Prochaines Ã‰tapes

AprÃ¨s la configuration de base, nous crÃ©erons :
1. `data_ingestion_dag.py` : Pour ingÃ©rer les donnÃ©es vers MinIO
2. `training_dag.py` : Pour orchestrer l'entraÃ®nement
3. `deployment_dag.py` : Pour dÃ©ployer les modÃ¨les

