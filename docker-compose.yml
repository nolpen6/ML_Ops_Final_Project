version: '3.8'

# Charger les variables d'environnement depuis .env
# Créer un fichier .env avec: AIRFLOW_FERNET_KEY=<your_key>
# Générer une clé avec: python3 -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

services:
  # MinIO - Object Storage (compatible S3)
  minio:
    image: minio/minio:latest
    container_name: mlops-minio
    ports:
      - "9000:9000"   # API
      - "9001:9001"   # Console web
    volumes:
      - minio_data:/data
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    networks:
      - mlops-network

  # MLflow Tracking Server
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlops-mlflow
    ports:
      - "5001:5000"  # Mappage sur 5001 car 5000 est déjà utilisé
    volumes:
      - ./mlruns:/mlflow/mlruns
    environment:
      - MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow/mlruns/mlflow.db
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=file:///mlflow/mlruns
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow/mlruns/mlflow.db --default-artifact-root file:///mlflow/mlruns
    depends_on:
      - minio
    networks:
      - mlops-network

  # PostgreSQL pour métadonnées Airflow
  postgres:
    image: postgres:15
    container_name: mlops-postgres
    ports:
      - "5433:5432"  # Mappage sur 5433 car 5432 est déjà utilisé
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: mlops
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  # pgAdmin - Interface web pour PostgreSQL
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: mlops-pgadmin
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@mlops.com
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      - postgres
    networks:
      - mlops-network

  # Redis pour Airflow (backend de queue)
  redis:
    image: redis:7-alpine
    container_name: mlops-redis
    ports:
      - "6379:6379"
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Airflow - Initialisation de la DB
  airflow-init:
    build:
      context: .
      dockerfile: docker/Dockerfile.airflow
    container_name: mlops-airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        function check_db() {
          python << END
        import sys
        import psycopg2
        try:
            conn = psycopg2.connect(
                host="postgres",
                user="airflow",
                password="airflow",
                dbname="mlops"
            )
            conn.close()
            sys.exit(0)
        except:
            sys.exit(1)
        END
        }
        until check_db; do
          echo "Waiting for PostgreSQL..."
          sleep 1
        done
        airflow db init
        airflow users create \
          --username admin \
          --firstname Admin \
          --lastname Admin \
          --role Admin \
          --email admin@example.com \
          --password admin
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/mlops
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/config:/opt/airflow/config
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - mlops-network

  # Airflow - Webserver
  airflow-webserver:
    build:
      context: .
      dockerfile: docker/Dockerfile.airflow
    container_name: mlops-airflow-webserver
    command: webserver
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/mlops
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/config:/opt/airflow/config
      - ./scripts:/opt/airflow/scripts
      - ./models:/opt/airflow/models
      - ./data:/opt/airflow/data
      - ./mlruns:/opt/airflow/mlruns
    depends_on:
      - airflow-init
      - postgres
      - redis
    networks:
      - mlops-network

  # Airflow - Scheduler
  airflow-scheduler:
    build:
      context: .
      dockerfile: docker/Dockerfile.airflow
    container_name: mlops-airflow-scheduler
    command: scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/mlops
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/config:/opt/airflow/config
      - ./scripts:/opt/airflow/scripts
      - ./models:/opt/airflow/models
      - ./data:/opt/airflow/data
      - ./mlruns:/opt/airflow/mlruns
    depends_on:
      - airflow-init
      - postgres
      - redis
    networks:
      - mlops-network

  # Prometheus - Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: mlops-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - mlops-network

  # Grafana - Visualisation
  grafana:
    image: grafana/grafana:latest
    container_name: mlops-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - mlops-network

volumes:
  minio_data:
  postgres_data:
  pgadmin_data:
  prometheus_data:
  grafana_data:

networks:
  mlops-network:
    driver: bridge

