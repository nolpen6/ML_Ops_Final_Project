# üöÄ Guide de D√©marrage - Projet MLOps

## üìç O√π en sommes-nous ?

Le repository **emmaloou/ML_Ops** est maintenant organis√© avec :
- ‚úÖ Scripts de base (data_preparation, model_train, api)
- ‚úÖ Configuration pour Airflow et MLflow
- ‚úÖ Docker Compose pour services locaux (MinIO, MLflow, PostgreSQL)
- ‚úÖ Roadmap d√©taill√©e dans `docs/ROADMAP_MLOps_PROJECT.md`
- ‚úÖ README principal
- ‚úÖ Requirements.txt

## üéØ Prochaines √âtapes (selon la roadmap)

### Phase 1 : Setup Local (Jours 1-2)

1. **Lancer les services avec Docker Compose**
```bash
cd /path/to/emmaloou-ML_Ops
docker-compose up -d
```

Cela lance :
- MinIO sur http://localhost:9000
- MLflow sur http://localhost:5000
- PostgreSQL sur localhost:5432

2. **Cr√©er le bucket MinIO**
```bash
# Via l'interface web http://localhost:9001
# ou avec mc (MinIO Client)
```

3. **T√©l√©charger le dataset**
```bash
# R√©cup√©rer les images depuis le repo de r√©f√©rence ou cr√©er vos dossiers
mkdir -p data/{grass,dandelion}
# Placer les images dans ces dossiers
```

### Phase 2 : Tests Locaux (Jours 3-4)

1. **Tester la pr√©paration des donn√©es**
```bash
python scripts/data_preparation.py
```

2. **Entra√Æner un premier mod√®le**
```bash
python scripts/model_train.py
```

3. **Tester l'API**
```bash
uvicorn scripts.api:app --reload
# Tester avec : curl -X POST http://localhost:8000/predict
```

### Phase 3 : Cr√©er les DAGs Airflow (Jours 5-7)

√Ä cr√©er dans le dossier `dags/` :
- `data_ingestion_dag.py` : Pour ing√©rer les donn√©es
- `training_dag.py` : Pour orchestrer l'entra√Ænement
- `model_deployment_dag.py` : Pour d√©ployer les mod√®les

### Phase 4 : Dockerisation (Jours 8-10)

√Ä cr√©er dans le dossier `docker/` :
- `Dockerfile.airflow` : Pour les DAGs Airflow
- `Dockerfile.api` : Pour l'API
- `Dockerfile.webapp` : Pour la WebApp

### Phase 5 : Kubernetes (Jours 11-13)

√Ä cr√©er dans le dossier `kubernetes/` :
- Manifests pour d√©ployer tous les services
- ConfigMaps et Secrets
- Services et Ingress

### Phase 6 : Monitoring & Finalisation (Jours 14-27)

- Setup Prometheus et Grafana
- Cr√©er les dashboards
- Finaliser la documentation
- Tests et validation

## üìÅ √Ä Compl√©ter (dossiers vides)

Ces dossiers sont cr√©√©s mais vides pour l'instant :
- `dags/` : √Ä ajouter les DAGs Airflow
- `docker/` : √Ä ajouter les Dockerfiles
- `kubernetes/` : √Ä ajouter les manifests K8s
- `monitoring/` : √Ä ajouter config Prometheus/Grafana

## üîó Ressources Utiles

- **Repo de r√©f√©rence** : https://github.com/btphan95/greenr-airflow.git
- **Documentation Airflow** : https://airflow.apache.org/docs/
- **Documentation MLflow** : https://www.mlflow.org/docs/
- **Documentation MinIO** : https://min.io/docs/
- **Documentation FastAPI** : https://fastapi.tiangolo.com/

## üí° Conseils

1. **Commencez simple** : Testez chaque script individuellement
2. **Versionnez** : Faites des commits fr√©quents
3. **Testez localement** : Docker Compose pour tout tester en local
4. **Suivez la roadmap** : `docs/ROADMAP_MLOps_PROJECT.md` contient les √©tapes d√©taill√©es

---

**C'est parti ! üöÄ**

